# Transformer
- A transformer is a deep-learning architecture that has an encoder component that converts the input text into embeddings. 
- It also has a decoder component that consumes the embeddings to emit some output text. 
- Unlike RNNs, transformers are extremely parallelizable, which means instead of processing text words one at a time during the learning cycle, transformers process input all at the same time. 
- It takes transformers significantly less time to train, but they require more computing power to speed training. 
- The transformer architecture was the key to the development of LLMs. 
- These days, most LLMs only contain a decoder component. 